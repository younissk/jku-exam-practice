[
    {
      "id": "1",
      "courseId": "qKGyw05W1UXklk4P9m6J",
      "source": "Exam",
      "year": "2023",
      "topics": ["Unit 4: Introduction to Reinforcement Learning"],
      "type": "MultipleChoice",
      "question": "Which of the following are parts of a Markov decision process?",
      "options": [
        "A set of possible rewards.",
        "A set of possible states.",
        "A set of possible actions.",
        "A set of possible state transitions."
      ],
      "correctAnswer": ["A set of possible states.", "A set of possible actions."]
    },
    {
      "id": "2",
      "courseId": "qKGyw05W1UXklk4P9m6J",
      "source": "Exam",
      "year": "2023",
      "topics": ["Unit 4: Introduction to Reinforcement Learning"],
      "type": "MultipleChoice",
      "question": "Assume a reinforcement learning scenario with a 2-dimensional location grid of size 10x10. Further assume that a robot (the agent) is placed randomly on this grid and must move to the target destination, which is also somewhere random on this grid. There are 4 possible movements: up, down, left and right. If the robot tries to go off the grid, it remains at the same location, but there will be a penalty of -5 (negative reward). Otherwise, move actions do not give any reward (0). If the robot reaches the target, +20 is awarded (positive reward). Which of the following statements are true?",
      "options": [
        "There can be policies A and B which are both optimal (w.r.t. the final reward) despite requiring a different total number of steps to reach the target destination.",
        "There are policies that reach the target destination but have a final reward of < 20.",
        "An optimal policy will give a final reward of 20.",
        "There are policies that never reach the target destination."
      ],
      "correctAnswer": [
        "An optimal policy will give a final reward of 20.",
        "There are policies that reach the target destination but have a final reward of < 20.",
        "There are policies that never reach the target destination.",
        "There can be policies A and B which are both optimal (w.r.t. the final reward) despite requiring a different total number of steps to reach the target destination."
      ]
    },
    {
      "id": "3",
      "courseId": "qKGyw05W1UXklk4P9m6J",
      "source": "Exam",
      "year": "2023",
      "topics": ["Unit 5: Drug Discovery"],
      "type": "MultipleChoice",
      "question": "The 3D structure of a molecule ...",
      "options": [
        "... determines its functionality.",
        "... is straightforward to predict if the sequence of atoms is known.",
        "... is expensive to determine experimentally.",
        "... can be different for the same molecular graph."
      ],
      "correctAnswer": [
        "... determines its functionality.",
        "... can be different for the same molecular graph.",
        "... is expensive to determine experimentally."
      ]
    },
    {
      "id": "4",
      "courseId": "qKGyw05W1UXklk4P9m6J",
      "source": "Exam",
      "year": "2023",
      "topics": ["Unit 5: Drug Discovery"],
      "type": "MultipleChoice",
      "question": "What are typical problems/challenges in traditional drug discovery?",
      "options": [
        "Success rates can be very low.",
        "It is a very long/time-consuming process.",
        "It is an expensive process.",
        "Finding suitable molecules is difficult and/or cumbersome because of the huge amount of possible candidates."
      ],
      "correctAnswer": [
        "It is an expensive process.",
        "It is a very long/time-consuming process.",
        "Finding suitable molecules is difficult and/or cumbersome because of the huge amount of possible candidates.",
        "Success rates can be very low."
      ]
    },
    {
      "id": "5",
      "courseId": "qKGyw05W1UXklk4P9m6J",
      "source": "Exam",
      "year": "2023",
      "topics": ["Unit 2: Vanishing Gradients"],
      "type": "MultipleChoice",
      "question": "Which of the following statements are true about the vanishing gradient problem?",
      "options": [
        "A vanishing gradient can be mitigated by decreasing the learning rate.",
        "Repeated multiplication of gradients smaller than 1 leads to a vanishing gradient.",
        "Repeated multiplication of gradients bigger than 1 leads to an vanishing gradient.",
        "The choice of the activation functions plays a crucial role in the vanishing gradient problem."
      ],
      "correctAnswer": [
        "Repeated multiplication of gradients smaller than 1 leads to a vanishing gradient.",
        "The choice of the activation functions plays a crucial role in the vanishing gradient problem."
      ]
    },
    {
      "id": "6",
      "courseId": "qKGyw05W1UXklk4P9m6J",
      "source": "Exam",
      "year": "2023",
      "topics": ["Unit 2: Vanishing Gradients"],
      "type": "MultipleChoice",
      "question": "Which of the following statements is/are true about the ReLU activation function?",
      "options": [
        "Its derivative is 0 for negative inputs.",
        "Its derivative is -x for negative input x.",
        "Its derivative is x for positive input x.",
        "Its derivative is 1 for positive inputs."
      ],
      "correctAnswer": [
        "Its derivative is 0 for negative inputs.",
        "Its derivative is 1 for positive inputs."
      ]
    },
    {
      "id": "7",
      "courseId": "qKGyw05W1UXklk4P9m6J",
      "source": "Exam",
      "year": "2023",
      "topics": ["Unit 2: Vanishing Gradients"],
      "type": "MultipleChoice",
      "question": "With respect to the vanishing gradient problem, which of the following statements are true regarding deep neural networks?",
      "options": [
        "The vanishing gradient problem will typically occur at the end of the network (towards the output layer).",
        "The vanishing gradient problem has no correlation with the depth, as it just depends on the activation functions.",
        "The vanishing gradient problem can get more severe when increasing the network depth.",
        "The deeper the network, the more multiplications (chain rule) we have to perform in the backward pass."
      ],
      "correctAnswer": [
        "The deeper the network, the more multiplications (chain rule) we have to perform in the backward pass.",
        "The vanishing gradient problem can get more severe when increasing the network depth."
      ]
    },
    {
      "id": "8",
      "courseId": "qKGyw05W1UXklk4P9m6J",
      "source": "Exam",
      "year": "2023",
      "topics": ["Unit 3: Recurrent Neural Networks"],
      "type": "MultipleChoice",
      "question": "The original CEC (constant error carousel) of an LSTM ...",
      "options": [
        "... uses non-linear functions to modify the cell state.",
        "... is responsible for going from the old cell state to the new cell state.",
        "... is the cause of the vanishing gradient problem.",
        "... is responsible for countering the vanishing gradient problem."
      ],
      "correctAnswer": [
        "... is responsible for countering the vanishing gradient problem.",
        "... is responsible for going from the old cell state to the new cell state."
      ]
    },
    {
      "id": "9",
      "courseId": "qKGyw05W1UXklk4P9m6J",
      "source": "Exam",
      "year": "2023",
      "topics": ["Unit 3: Recurrent Neural Networks"],
      "type": "MultipleChoice",
      "question": "In classification, ...",
      "options": [
        "... the target can be a number.",
        "... we are dealing with an unsupervised machine learning scenario.",
        "... there can only be two classes.",
        "... the target value is a class label."
      ],
      "correctAnswer": [
        "... the target value is a class label.",
        "... the target can be a number."
      ]
    },
    {
      "id": "10",
      "courseId": "qKGyw05W1UXklk4P9m6J",
      "source": "Exam",
      "year": "2023",
      "topics": ["Unit 4: Introduction to Reinforcement Learning"],
      "type": "MultipleChoice",
      "question": "In Q-learning, an action must be taken to update the Q-values. Which of the following statements are true?",
      "options": [
        "\"Exploration\" and \"Exploitation\" are strategies for choosing actions.",
        "The action can be chosen based on the current highest Q-value.",
        "Depending on the environment, choosing a suboptimal action might lead to Q-learning getting stuck.",
        "The action can be chosen randomly."
      ],
      "correctAnswer": [
        "The action can be chosen randomly.",
        "The action can be chosen based on the current highest Q-value.",
        "Depending on the environment, choosing a suboptimal action might lead to Q-learning getting stuck.",
        "\"Exploration\" and \"Exploitation\" are strategies for choosing actions."
      ]
    },
    {
      "id": "11",
      "courseId": "qKGyw05W1UXklk4P9m6J",
      "source": "Exam",
      "year": "2023",
      "topics": ["Unit 3: Recurrent Neural Networks"],
      "type": "MultipleChoice",
      "question": "Which of the following statements are true about the weights of an RNN?",
      "options": [
        "The size of the weight matrix is independent of the sequence length.",
        "For each timestep, a dedicated weight matrix is used.",
        "For each timestep, the same (shared) weight matrix is used.",
        "For sequences of different length, multiple (shared) weight matrices must be learned (one for each unique sequence length)."
      ],
      "correctAnswer": [
        "For each timestep, the same (shared) weight matrix is used.",
        "The size of the weight matrix is independent of the sequence length."
      ]
    },
    {
      "id": "12",
      "courseId": "qKGyw05W1UXklk4P9m6J",
      "source": "Exam",
      "year": "2023",
      "topics": ["Unit 1: Recap of HoAI 1"],
      "type": "MultipleChoice",
      "question": "Which of the following formulae are correct regarding the forward pass in a neural network layer, given some input vector x, weight matrix W, bias b and non-linear function f? You can assume that all vectors and matrices are in correct shape.",
      "options": [
        "output = f(x * W) + b",
        "output = x * f(W + b)",
        "output = f(x * W + b)",
        "output = f(x) * W + b"
      ],
      "correctAnswer": ["output = f(x * W + b)"]
    },
    {
      "id": "13",
      "courseId": "qKGyw05W1UXklk4P9m6J",
      "source": "Exam",
      "year": "2023",
      "topics": ["Unit 3: Recurrent Neural Networks"],
      "type": "MultipleChoice",
      "question": "Which of the following statements are true about many-to-many RNN types?",
      "options": [
        "Given an input of length Tx = 1, the output/prediction length is Ty = 1.",
        "Given an input of length Tx > 1, the output/prediction length is Ty = 1.",
        "Given an input of length Tx, the output/prediction length can be unequal, i.e., Tx ≠ Ty.",
        "Given an input of length Tx, the output/prediction length can be equal, i.e., Tx = Ty."
      ],
      "correctAnswer": [
        "Given an input of length Tx, the output/prediction length can be equal, i.e., Tx = Ty.",
        "Given an input of length Tx, the output/prediction length can be unequal, i.e., Tx ≠ Ty."
      ]
    },
    {
      "id": "14",
      "courseId": "qKGyw05W1UXklk4P9m6J",
      "source": "Exam",
      "year": "2023",
      "topics": ["Unit 6: Language Modeling"],
      "type": "MultipleChoice",
      "question": "Assume a language modeling scenario where you have a dictionary size of 900, an embedding size of 250 and a hidden representation size of 200. Which of the following statements are true when considering a single model input (one word)?",
      "options": [
        "The decoder results in an output of size 900.",
        "The model output are probabilities that sum up to 1.",
        "The encoder and decoder matrices have equally many parameters.",
        "The encoder matrix is identical to the decoder matrix."
      ],
      "correctAnswer": [
        "The decoder results in an output of size 900.",
        "The model output are probabilities that sum up to 1."
      ]
    },
    {
      "id": "15",
      "courseId": "qKGyw05W1UXklk4P9m6J",
      "source": "Exam",
      "year": "2023",
      "topics": ["Unit 2: Vanishing Gradients"],
      "type": "MultipleChoice",
      "question": "Which of the following activation functions are prone to the vanishing gradient problem?",
      "options": ["Leaky ReLU", "Tanh", "ReLU", "Sigmoid"],
      "correctAnswer": ["Sigmoid", "Tanh"]
    },
    {
      "id": "16",
      "courseId": "qKGyw05W1UXklk4P9m6J",
      "source": "Exam",
      "year": "2023",
      "topics": ["Unit 4: Introduction to Reinforcement Learning"],
      "type": "MultipleChoice",
      "question": "Which of the following statements are true about the concept of an optimal policy?",
      "options": [
        "Q-learning is an optimal policy.",
        "There can be multiple optimal policies.",
        "It maximizes the sum of rewards.",
        "Continuously choosing the actions with the highest immediate reward will lead to an optimal policy."
      ],
      "correctAnswer": [
        "It maximizes the sum of rewards.",
        "There can be multiple optimal policies."
      ]
    },
    {
      "id": "17",
      "courseId": "qKGyw05W1UXklk4P9m6J",
      "source": "Exam",
      "year": "2023",
      "topics": ["Unit 5: Drug Discovery"],
      "type": "MultipleChoice",
      "question": "Which of the following statements are true about SMILES (Simplified Molecular Input Line Entry Specification)?",
      "options": [
        "A molecule can have different SMILES representations.",
        "SIMLES is one of many molecular representations.",
        "It is a string sequence representation of a molecule.",
        "A molecule can only have exactly one SIMLES representation."
      ],
      "correctAnswer": [
        "It is a string sequence representation of a molecule.",
        "A molecule can have different SMILES representations.",
        "SIMLES is one of many molecular representations."
      ]
    },
    {
      "id": "18",
      "courseId": "qKGyw05W1UXklk4P9m6J",
      "source": "Exam",
      "year": "2023",
      "topics": ["Unit 1: Recap of HoAI 1"],
      "type": "MultipleChoice",
      "question": "Which of the following statements are true about data augmentation?",
      "options": [
        "Some data augmentation techniques (e.g., noise) can be theoretically applied to all kinds of data.",
        "Data augmentation might increase the robustness of a model.",
        "Data augmentation is useful to remove duplicate samples.",
        "Data augmentation reduces underfitting."
      ],
      "correctAnswer": [
        "Some data augmentation techniques (e.g., noise) can be theoretically applied to all kinds of data.",
        "Data augmentation might increase the robustness of a model."
      ]
    },
    {
      "id": "19",
      "courseId": "qKGyw05W1UXklk4P9m6J",
      "source": "Exam",
      "year": "2023",
      "topics": ["Unit 6: Language Modeling"],
      "type": "MultipleChoice",
      "question": "Which of the following statements is/are true about language models?",
      "options": [
        "Language modeling is the task of predicting a word given a context.",
        "Language modeling is the task of predicting a context given a word.",
        "Language modeling is the task of predicting a previously unseen word.",
        "Language modeling is the task of predicting the importance of words."
      ],
      "correctAnswer": ["Language modeling is the task of predicting a word given a context."]
    },
    {
      "id": "20",
      "courseId": "qKGyw05W1UXklk4P9m6J",
      "source": "Exam",
      "year": "2023",
      "topics": ["Unit 1: Recap of HoAI 1"],
      "type": "MultipleChoice",
      "question": "A non-convex function ...",
      "options": [
        "... typically does not have a closed-form solution.",
        "... is common in deep learning.",
        "... often requires iterative methods when calculating the minimum.",
        "... must always be solved analytically when calculating the minimum."
      ],
      "correctAnswer": [
        "... is common in deep learning.",
        "... typically does not have a closed-form solution.",
        "... often requires iterative methods when calculating the minimum."
      ]
    },
    {
      "id": "21",
      "courseId": "qKGyw05W1UXklk4P9m6J",
      "source": "Exam",
      "year": "2023",
      "topics": ["Unit 3: Recurrent Neural Networks"],
      "type": "MultipleChoice",
      "question": "Back-propagation through time ...",
      "options": [
        "... generates (potentially) very deep neworks.",
        "... is the cause of vanishing gradients in RNNs.",
        "... mitigates the vanishing gradients problem in unrolled RNNs.",
        "... is commonly used to train an RNN."
      ],
      "correctAnswer": [
        "... is commonly used to train an RNN.",
        "... generates (potentially) very deep neworks."
      ]
    },
    {
      "id": "22",
      "courseId": "qKGyw05W1UXklk4P9m6J",
      "source": "Exam",
      "year": "2023",
      "topics": ["Unit 1: Recap of HoAI 1"],
      "type": "MultipleChoice",
      "question": "Which of the following are typical activation functions in neural networks?",
      "options": ["Leaky ReLU", "Sigmoid", "ReLU", "Tanh"],
      "correctAnswer": ["Sigmoid", "ReLU", "Tanh", "Leaky ReLU"]
    },
    {
      "id": "23",
      "courseId": "qKGyw05W1UXklk4P9m6J",
      "source": "Exam",
      "year": "2023",
      "topics": ["Unit 3: Recurrent Neural Networks"],
      "type": "MultipleChoice",
      "question": "Which of the following statements are true about recurrent neural networks?",
      "options": [
        "They are suitable for processing sequences of variable dimensionality (i.e. number of features).",
        "They are suitable for processing sequences of variable length.",
        "They are the same as regular feed-forward neural networks in case the sequence length is fixed.",
        "They are suitable for processing sequences of fixed length."
      ],
      "correctAnswer": [
        "They are suitable for processing sequences of variable length.",
        "They are suitable for processing sequences of fixed length."
      ]
    },
    {
      "id": "24",
      "courseId": "qKGyw05W1UXklk4P9m6J",
      "source": "Exam",
      "year": "2023",
      "topics": ["Unit 5: Drug Discovery"],
      "type": "MultipleChoice",
      "question": "Which of the following statements are true about virtual screening (VS)?",
      "options": [
        "In VS, a trained neural network predicts the 3D structure of an amino-acid sequence.",
        "In VS, a trained neural network predicts whether a molecule in the data base is likely to bind/react with the target of interest.",
        "In VS, a trained neural network virtually searches through the whole chemical universe in order to find molecules with a specific bio-activity.",
        "In VS, a trained neural network creates new molecules with the specified bio-activity."
      ],
      "correctAnswer": [
        "In VS, a trained neural network predicts whether a molecule in the data base is likely to bind/react with the target of interest."
      ]
    },
    {
      "id": "25",
      "courseId": "qKGyw05W1UXklk4P9m6J",
      "source": "Exam",
      "year": "2023",
      "topics": ["Unit 4: Introduction to Reinforcement Learning"],
      "type": "MultipleChoice",
      "question": "Consider the update function used during Q-learning: Q(s, a) ← (1 - α) * Q(s, a) + α * (r + γ * max Q(s', a')). Which of the following statements are true?",
      "options": [
        "r is the expected long-term reward when taking action a in state s.",
        "α is the learning rate.",
        "α = 0 means that only new information is used in the update.",
        "α = 1 means that only new information is used in the update."
      ],
      "correctAnswer": ["α is the learning rate.", "α = 1 means that only new information is used in the update."]
    },
    {
      "id": "26",
      "courseId": "qKGyw05W1UXklk4P9m6J",
      "source": "Exam",
      "year": "2023",
      "topics": ["Unit 5: Drug Discovery"],
      "type": "MultipleChoice",
      "question": "A drug is ...",
      "options": [
        "... a chemical substance which should ideally suppress all biological effects in a living organism.",
        "... equivalent to a nutrient or an essential dietary ingredient (they are all synonymous).",
        "... a chemical substance which produces a biological effect in a living organism when administered.",
        "... a type of non-linear activation function for neural networks in life sciences."
      ],
      "correctAnswer": ["... a chemical substance which produces a biological effect in a living organism when administered."]
    },
    {
      "id": "27",
      "courseId": "qKGyw05W1UXklk4P9m6J",
      "source": "Exam",
      "year": "2023",
      "topics": ["Unit 1: Recap of HoAI 1"],
      "type": "MultipleChoice",
      "question": "In convolutional neural networks, which of the following statements are true about weight sharing?",
      "options": [
        "It is about applying the kernel to all image positions while keeping the weights the same.",
        "It is about applying the kernel to all image positions while continuously updating the weights.",
        "It is about applying the kernel to one specific image position while continuously updating the weights.",
        "It is about applying the kernel to one specific image position while keeping the weights the same."
      ],
      "correctAnswer": ["It is about applying the kernel to all image positions while keeping the weights the same."]
    },
    {
      "id": "28",
      "courseId": "qKGyw05W1UXklk4P9m6J",
      "source": "Exam",
      "year": "2023",
      "topics": ["Unit 4: Introduction to Reinforcement Learning"],
      "type": "MultipleChoice",
      "question": "Which of the following statements is/are true about Q-learning?",
      "options": [
        "Q-learning is one possible implementation of reinforcement learning.",
        "Q-learning quickly becomes computationally infeasible for larger MDPs (Markov decision processes).",
        "Q-learning can be applied to any MDP (Markov decision process).",
        "Deep Q-learning is about approximating the Q-value function."
      ],
      "correctAnswer": [
        "Q-learning can be applied to any MDP (Markov decision process).",
        "Q-learning is one possible implementation of reinforcement learning.",
        "Q-learning quickly becomes computationally infeasible for larger MDPs (Markov decision processes).",
        "Deep Q-learning is about approximating the Q-value function."
      ]
    },
    {
      "id": "29",
      "courseId": "qKGyw05W1UXklk4P9m6J",
      "source": "Exam",
      "year": "2023",
      "topics": ["Unit 1: Recap of HoAI 1"],
      "type": "MultipleChoice",
      "question": "Which of the following statements are true regarding a loss function?",
      "options": [
        "It measures how close the prediction is to the true target.",
        "Given two losses lossA and lossB obtained with two different functions, then the one function which yielded the lower loss is the better function.",
        "Typically, the lower the loss, the better the prediction.",
        "Typically, the higher the loss, the better the prediction."
      ],
      "correctAnswer": [
        "It measures how close the prediction is to the true target.",
        "Typically, the lower the loss, the better the prediction."
      ]
    }
  ]
  